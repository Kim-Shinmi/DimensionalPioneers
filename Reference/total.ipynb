{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO5jMYctooCffEkmbt1pI3Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2190fbf0b9334f428537a6757f7bf156":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f72b7aa82fe4d1f8bb999c8d63fa829","IPY_MODEL_6604e613b7524c92a214713ef9cb3515","IPY_MODEL_04840bf9d8da48aca75b2a951cf2e185"],"layout":"IPY_MODEL_14b59625954f4947a77e2c3af9a6fe7b","tabbable":null,"tooltip":null}},"2f72b7aa82fe4d1f8bb999c8d63fa829":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a80b906daf6b46e7802650093abef712","placeholder":"​","style":"IPY_MODEL_addb2bfc096f4843bb83c0caec59b395","tabbable":null,"tooltip":null,"value":""}},"6604e613b7524c92a214713ef9cb3515":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f64a9ad23e124c3aa9f5c9ffe873d21b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c6f3001385b4e37800451953e526765","tabbable":null,"tooltip":null,"value":0}},"04840bf9d8da48aca75b2a951cf2e185":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_8ccb2d1fd4194d11887b6e199c9bacc4","placeholder":"​","style":"IPY_MODEL_2f1ce1464e5b4d5a809213a6beee1b0a","tabbable":null,"tooltip":null,"value":" 0/0 [00:00&lt;?, ?it/s]"}},"14b59625954f4947a77e2c3af9a6fe7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a80b906daf6b46e7802650093abef712":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"addb2bfc096f4843bb83c0caec59b395":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f64a9ad23e124c3aa9f5c9ffe873d21b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3c6f3001385b4e37800451953e526765":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ccb2d1fd4194d11887b6e199c9bacc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f1ce1464e5b4d5a809213a6beee1b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d79b33462bc0453d9e71e30aa8cbbb0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72831fb763594a3ca7946f246cf9420c","IPY_MODEL_79b7f66e16a64616a369760b71223aad","IPY_MODEL_97289a8d63a443c08744a6443d020656"],"layout":"IPY_MODEL_98f2c1644e8845e88735e1a7ae6ccd45","tabbable":null,"tooltip":null}},"72831fb763594a3ca7946f246cf9420c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_96abc68dfc1b4d1cb285b6e7dcee6e07","placeholder":"​","style":"IPY_MODEL_b8714f1687864417a26359058ededa42","tabbable":null,"tooltip":null,"value":"Loading pipeline components...: 100%"}},"79b7f66e16a64616a369760b71223aad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_7c41f5fefed0404bbfee41951a38a36a","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7add9091de3f4e2ab1c0b85fcd559dc6","tabbable":null,"tooltip":null,"value":8}},"97289a8d63a443c08744a6443d020656":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_4186acbef681430487246f1004a3921c","placeholder":"​","style":"IPY_MODEL_74c577cfd0fc4fafb47b187533a2347f","tabbable":null,"tooltip":null,"value":" 8/8 [01:07&lt;00:00,  7.21s/it]"}},"98f2c1644e8845e88735e1a7ae6ccd45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96abc68dfc1b4d1cb285b6e7dcee6e07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8714f1687864417a26359058ededa42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"7c41f5fefed0404bbfee41951a38a36a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7add9091de3f4e2ab1c0b85fcd559dc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4186acbef681430487246f1004a3921c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c577cfd0fc4fafb47b187533a2347f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"0595cad7840a40b1aef2cf1777b1a2be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90e908be205c4f5aacab72df79576f9e","IPY_MODEL_14ece3422d314c9ab3328ba9471fd34f","IPY_MODEL_d391c9baf71b411b997b1fc2ad39f724"],"layout":"IPY_MODEL_48368938bc2f425e8f263415213d86e1","tabbable":null,"tooltip":null}},"90e908be205c4f5aacab72df79576f9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_976afb6ea13f4328b1da0ccfded695bb","placeholder":"​","style":"IPY_MODEL_ff892b8542db45d7b9edae762021189e","tabbable":null,"tooltip":null,"value":"100%"}},"14ece3422d314c9ab3328ba9471fd34f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_af28a1b2d5194df5a30a2b759a556425","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_733dad0565a04ed7b132455e42e52f19","tabbable":null,"tooltip":null,"value":100}},"d391c9baf71b411b997b1fc2ad39f724":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5b32e13b805846878b779913a7b56ba7","placeholder":"​","style":"IPY_MODEL_758201d5cd9e49b4b6ba54ccb701dee6","tabbable":null,"tooltip":null,"value":" 100/100 [00:54&lt;00:00,  1.76it/s]"}},"48368938bc2f425e8f263415213d86e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"976afb6ea13f4328b1da0ccfded695bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff892b8542db45d7b9edae762021189e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"af28a1b2d5194df5a30a2b759a556425":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"733dad0565a04ed7b132455e42e52f19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b32e13b805846878b779913a7b56ba7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"758201d5cd9e49b4b6ba54ccb701dee6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"05eef6e9be30431f9e0a7722692d3425":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b995b25286654733a441453302c2ed07","IPY_MODEL_cd3d02767f0b46f7aa38147794191f7e","IPY_MODEL_b1150188aefc4d28a12609c5671c38e3"],"layout":"IPY_MODEL_96a4f20bd2514d63a5c9574097b6874a","tabbable":null,"tooltip":null}},"b995b25286654733a441453302c2ed07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_958f396e296a4ec08579b973f29aaa39","placeholder":"​","style":"IPY_MODEL_8905f353f9fc4404a77db6f7bdaa7224","tabbable":null,"tooltip":null,"value":"Loading pipeline components...: 100%"}},"cd3d02767f0b46f7aa38147794191f7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_5672744e1c37479ab9663c894b5e77e7","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f6ad8f0b72e42fda42eceaf8ef2694e","tabbable":null,"tooltip":null,"value":8}},"b1150188aefc4d28a12609c5671c38e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c462023ef6394d428fa9d7a32319bff6","placeholder":"​","style":"IPY_MODEL_95058e00f8e149fa9610b45534687272","tabbable":null,"tooltip":null,"value":" 8/8 [00:03&lt;00:00,  2.56it/s]"}},"96a4f20bd2514d63a5c9574097b6874a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"958f396e296a4ec08579b973f29aaa39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8905f353f9fc4404a77db6f7bdaa7224":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5672744e1c37479ab9663c894b5e77e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f6ad8f0b72e42fda42eceaf8ef2694e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c462023ef6394d428fa9d7a32319bff6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95058e00f8e149fa9610b45534687272":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b30c1598bf6741bab46152dfa31c282d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e013ed9cb85547bab105e2f1c3246813","IPY_MODEL_2f6cda8207144b6da64893a5c14f8e5c","IPY_MODEL_469d9f1342de475aa54b2f93b15b6168"],"layout":"IPY_MODEL_854d90fc0b8941d69d522bbfd185f01a","tabbable":null,"tooltip":null}},"e013ed9cb85547bab105e2f1c3246813":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e7f2730561714d8fa4225e4e35b88a93","placeholder":"​","style":"IPY_MODEL_c00f46d7edd844dead3ebc01ef9b5e27","tabbable":null,"tooltip":null,"value":"100%"}},"2f6cda8207144b6da64893a5c14f8e5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_d1c08b8585e94b18ab9339b2873dadf1","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e4b7f7ae08a4e2191de31869898f473","tabbable":null,"tooltip":null,"value":100}},"469d9f1342de475aa54b2f93b15b6168":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_86a727e3b8354092b08baf7e2a7145a0","placeholder":"​","style":"IPY_MODEL_b0d9fd95a2ce4320bfb4a71d6f5fd7f2","tabbable":null,"tooltip":null,"value":" 100/100 [01:00&lt;00:00,  1.73it/s]"}},"854d90fc0b8941d69d522bbfd185f01a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7f2730561714d8fa4225e4e35b88a93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c00f46d7edd844dead3ebc01ef9b5e27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d1c08b8585e94b18ab9339b2873dadf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4b7f7ae08a4e2191de31869898f473":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86a727e3b8354092b08baf7e2a7145a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0d9fd95a2ce4320bfb4a71d6f5fd7f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}}}},"cells":[{"cell_type":"markdown","source":["# 사용준비"],"metadata":{"id":"Qpb3KrXcTY4W"}},{"cell_type":"markdown","source":["## 구글 드라이브 임포트"],"metadata":{"id":"2gO5REddWcNp"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2IeBt9t34PLA","executionInfo":{"status":"ok","timestamp":1713160326024,"user_tz":-540,"elapsed":2743,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"30ec54c2-3ffd-4bb6-c23b-cf3939a98a72"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## 작업 디렉토리 이동"],"metadata":{"id":"N92RhCO6WfVP"}},{"cell_type":"code","source":["cd /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzBbJ6jgUsF7","executionInfo":{"status":"ok","timestamp":1713160326024,"user_tz":-540,"elapsed":5,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"474286c2-7f74-456f-cc23-3e5afd27e300"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total\n"]}]},{"cell_type":"markdown","source":["## DUST3R 필요 lib다운(설치후 재실행 해야함)"],"metadata":{"id":"Le9s5gXfWiND"}},{"cell_type":"code","source":["!pip install -r requirements.txt\n","!pip install -r requirements_optional.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_FYtLc3WZ11","executionInfo":{"status":"ok","timestamp":1713160357696,"user_tz":-540,"elapsed":26327,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"6c08b8f6-b6e7-4c91-abe4-058ceb2f3fe4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.17.1+cu121)\n","Requirement already satisfied: roma in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.4.5)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.26.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.8.0.76)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.11.4)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.7.0)\n","Requirement already satisfied: trimesh in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.3.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.15.2)\n","Requirement already satisfied: pyglet<2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.5.28)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.4.127)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (10.0.1)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (4.2.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.110.1)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.3.2)\n","Requirement already satisfied: gradio-client==0.15.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.15.1)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.27.0)\n","Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.20.3)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (6.4.0)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.1.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (3.10.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (24.0)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.0.3)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.6.4)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.0.9)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (6.0.1)\n","Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.3.7)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.10.0)\n","Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.12.0)\n","Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.9.4)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.29.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio->-r requirements.txt (line 4)) (11.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.62.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.0.2)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 11)) (1.3.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (3.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (0.14.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 4)) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 4)) (2024.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 4)) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 4)) (2.16.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (2.0.7)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (8.1.7)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (0.4.6)\n","Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (1.5.4)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (13.7.1)\n","Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 4)) (0.37.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (0.34.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (0.18.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 11)) (3.2.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (0.1.2)\n","Requirement already satisfied: pillow-heif in /usr/local/lib/python3.10/dist-packages (from -r requirements_optional.txt (line 1)) (0.16.0)\n","Requirement already satisfied: pillow>=9.5.0 in /usr/local/lib/python3.10/dist-packages (from pillow-heif->-r requirements_optional.txt (line 1)) (10.0.1)\n"]}]},{"cell_type":"markdown","source":["## ZERO123++ 필요 lib다운"],"metadata":{"id":"8To5WjmKWp9L"}},{"cell_type":"code","source":["!pip install rembg\n","!pip install cog\n","!pip install diffusers\n","!pip install transformers\n","!pip install torch\n","!pip install accelerate\n","!pip install colmap-wrapper\n","!pip install PyOpenGL\n","!pip install PyOpenGL_accelerate\n","!pip install glfw"],"metadata":{"id":"2tCtAiBj-LWk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713160463747,"user_tz":-540,"elapsed":106070,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"495d45bf-2445-475e-ca8c-47d8874b36f4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rembg in /usr/local/lib/python3.10/dist-packages (2.0.56)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from rembg) (4.19.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rembg) (1.25.2)\n","Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from rembg) (1.17.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from rembg) (4.9.0.80)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from rembg) (10.0.1)\n","Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from rembg) (1.8.1)\n","Requirement already satisfied: pymatting in /usr/local/lib/python3.10/dist-packages (from rembg) (1.1.12)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from rembg) (0.19.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from rembg) (1.11.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from rembg) (4.66.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg) (0.34.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg) (0.18.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (24.3.25)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (24.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (1.12)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->rembg) (4.2.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch->rembg) (2.31.0)\n","Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.10/dist-packages (from pymatting->rembg) (0.58.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (3.3)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (2024.2.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (1.6.0)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.41.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (2024.2.2)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime->rembg) (10.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->rembg) (1.3.0)\n","Collecting cog\n","  Using cached cog-0.9.5-py3-none-any.whl (90 kB)\n","Requirement already satisfied: attrs<24,>=20.1 in /usr/local/lib/python3.10/dist-packages (from cog) (23.2.0)\n","Collecting fastapi<0.99.0,>=0.75.2 (from cog)\n","  Using cached fastapi-0.98.0-py3-none-any.whl (56 kB)\n","Collecting pydantic<2,>=1.9 (from cog)\n","  Using cached pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from cog) (6.0.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from cog) (2.31.0)\n","Collecting structlog<25,>=20 (from cog)\n","  Using cached structlog-24.1.0-py3-none-any.whl (65 kB)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from cog) (4.11.0)\n","Requirement already satisfied: uvicorn[standard]<1,>=0.12 in /usr/local/lib/python3.10/dist-packages (from cog) (0.29.0)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.99.0,>=0.75.2->cog)\n","  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->cog) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->cog) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->cog) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->cog) (2024.2.2)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]<1,>=0.12->cog) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]<1,>=0.12->cog) (0.14.0)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]<1,>=0.12->cog)\n","  Using cached httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]<1,>=0.12->cog)\n","  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]<1,>=0.12->cog)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]<1,>=0.12->cog)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]<1,>=0.12->cog) (11.0.3)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.99.0,>=0.75.2->cog) (3.7.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.99.0,>=0.75.2->cog) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.99.0,>=0.75.2->cog) (1.2.0)\n","Installing collected packages: uvloop, structlog, python-dotenv, pydantic, httptools, watchfiles, starlette, fastapi, cog\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.6.4\n","    Uninstalling pydantic-2.6.4:\n","      Successfully uninstalled pydantic-2.6.4\n","  Attempting uninstall: starlette\n","    Found existing installation: starlette 0.37.2\n","    Uninstalling starlette-0.37.2:\n","      Successfully uninstalled starlette-0.37.2\n","  Attempting uninstall: fastapi\n","    Found existing installation: fastapi 0.110.1\n","    Uninstalling fastapi-0.110.1:\n","      Successfully uninstalled fastapi-0.110.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gradio 4.26.0 requires pydantic>=2.0, but you have pydantic 1.10.15 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cog-0.9.5 fastapi-0.98.0 httptools-0.6.1 pydantic-1.10.15 python-dotenv-1.0.1 starlette-0.27.0 structlog-24.1.0 uvloop-0.19.0 watchfiles-0.21.0\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.27.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.4)\n","Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.20.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (10.0.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (24.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting accelerate\n","  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.29.2\n","Collecting colmap-wrapper\n","  Downloading colmap_wrapper-1.1.5-py3-none-any.whl (22 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colmap-wrapper) (1.25.2)\n","Collecting pyexiftool (from colmap-wrapper)\n","  Downloading PyExifTool-0.5.6-py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting open3d (from colmap-wrapper)\n","  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyquaternion (from colmap-wrapper)\n","  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from colmap-wrapper) (3.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colmap-wrapper) (4.66.2)\n","Collecting wget (from colmap-wrapper)\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pycolmap (from colmap-wrapper)\n","  Downloading pycolmap-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->colmap-wrapper) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->colmap-wrapper) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->colmap-wrapper) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->colmap-wrapper) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->colmap-wrapper) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->colmap-wrapper) (10.0.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->colmap-wrapper) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->colmap-wrapper) (2.8.2)\n","Collecting dash>=2.6.0 (from open3d->colmap-wrapper)\n","  Downloading dash-2.16.1-py3-none-any.whl (10.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d->colmap-wrapper) (3.0.2)\n","Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d->colmap-wrapper) (5.10.4)\n","Collecting configargparse (from open3d->colmap-wrapper)\n","  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n","Collecting ipywidgets>=8.0.4 (from open3d->colmap-wrapper)\n","  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting addict (from open3d->colmap-wrapper)\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d->colmap-wrapper) (2.0.3)\n","Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d->colmap-wrapper) (6.0.1)\n","Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d->colmap-wrapper) (1.2.2)\n","Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d->colmap-wrapper) (2.2.5)\n","Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d->colmap-wrapper) (5.15.0)\n","Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d->colmap-wrapper)\n","  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n","Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d->colmap-wrapper)\n","  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n","Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d->colmap-wrapper)\n","  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d->colmap-wrapper) (7.1.0)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d->colmap-wrapper) (4.11.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d->colmap-wrapper) (2.31.0)\n","Collecting retrying (from dash>=2.6.0->open3d->colmap-wrapper)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d->colmap-wrapper) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d->colmap-wrapper) (67.7.2)\n","Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d->colmap-wrapper)\n","  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n","Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d->colmap-wrapper) (7.34.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d->colmap-wrapper) (5.7.1)\n","Collecting widgetsnbextension~=4.0.10 (from ipywidgets>=8.0.4->open3d->colmap-wrapper)\n","  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d->colmap-wrapper) (3.0.10)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d->colmap-wrapper) (2.19.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d->colmap-wrapper) (4.19.2)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d->colmap-wrapper) (5.7.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d->colmap-wrapper) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d->colmap-wrapper) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->colmap-wrapper) (1.16.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d->colmap-wrapper) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d->colmap-wrapper) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d->colmap-wrapper) (3.4.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d->colmap-wrapper) (2.1.5)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d->colmap-wrapper) (3.1.3)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d->colmap-wrapper) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d->colmap-wrapper) (8.1.7)\n","Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (4.9.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d->colmap-wrapper) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d->colmap-wrapper) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d->colmap-wrapper) (0.34.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d->colmap-wrapper) (0.18.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d->colmap-wrapper) (4.2.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d->colmap-wrapper) (8.2.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d->colmap-wrapper) (3.18.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d->colmap-wrapper) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d->colmap-wrapper) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d->colmap-wrapper) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d->colmap-wrapper) (2024.2.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d->colmap-wrapper) (0.2.13)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=4278c37e50e1c86b62c671e6dec0f1d0fc5b7faf396b0a05c4804c2d3f73808b\n","  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n","Successfully built wget\n","Installing collected packages: wget, dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, retrying, pyquaternion, pyexiftool, pycolmap, jedi, configargparse, comm, ipywidgets, dash, open3d, colmap-wrapper\n","  Attempting uninstall: widgetsnbextension\n","    Found existing installation: widgetsnbextension 3.6.6\n","    Uninstalling widgetsnbextension-3.6.6:\n","      Successfully uninstalled widgetsnbextension-3.6.6\n","  Attempting uninstall: ipywidgets\n","    Found existing installation: ipywidgets 7.7.1\n","    Uninstalling ipywidgets-7.7.1:\n","      Successfully uninstalled ipywidgets-7.7.1\n","Successfully installed addict-2.4.0 colmap-wrapper-1.1.5 comm-0.2.2 configargparse-1.7 dash-2.16.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.2 jedi-0.19.1 open3d-0.18.0 pycolmap-0.6.1 pyexiftool-0.5.6 pyquaternion-0.9.9 retrying-1.3.4 wget-3.2 widgetsnbextension-4.0.10\n","Requirement already satisfied: PyOpenGL in /usr/local/lib/python3.10/dist-packages (3.1.7)\n","Collecting PyOpenGL_accelerate\n","  Downloading PyOpenGL_accelerate-3.1.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyOpenGL_accelerate\n","Successfully installed PyOpenGL_accelerate-3.1.7\n","Collecting glfw\n","  Downloading glfw-2.7.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: glfw\n","Successfully installed glfw-2.7.0\n"]}]},{"cell_type":"markdown","source":["## 확인중"],"metadata":{"id":"_bShsUjcWwj9"}},{"cell_type":"code","source":["!sudo apt-get update\n","!sudo apt-get install -y colmap"],"metadata":{"id":"bDWMKIUZ-Xp6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Zero123++ 사용코드"],"metadata":{"id":"UQhLQ2fjTQf1"}},{"cell_type":"code","source":["import os\n","import subprocess\n","from typing import List\n","import cv2\n","import rembg\n","import torch\n","from cog import BasePredictor, Input, Path\n","from diffusers import DiffusionPipeline, EulerAncestralDiscreteScheduler\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","class Predictor(BasePredictor):\n","    def setup(self) -> None:\n","        \"\"\"Load the model into memory to make running multiple predictions efficient\"\"\"\n","\n","        if not os.path.exists(\"weights\"):\n","            os.mkdir(\"weights\")\n","\n","\n","        print(\"Setting up pipeline...\")\n","\n","        self.pipeline = DiffusionPipeline.from_pretrained(\n","            \"/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/weights/zero123plusplus\",\n","            custom_pipeline=\"/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/diffusers-support/\",\n","            torch_dtype=torch.float16,\n","            local_files_only=True\n","        )\n","        self.pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(\n","            self.pipeline.scheduler.config, timestep_spacing='trailing'\n","        )\n","        self.pipeline.to('cuda:0')\n","\n","    def predict(\n","        self,\n","        image: Path = Input(description=\"Input image. Aspect ratio should be 1:1. Recommended resolution is >= 320x320 pixels.\"),\n","        remove_background: bool = Input(description=\"Remove the background of the input image\", default=False),\n","        return_intermediate_images: bool = Input(description=\"Return the intermediate images together with the output images\", default=False),\n","    ) -> List[Path]:\n","        \"\"\"Run a single prediction on the model\"\"\"\n","        outputs = []\n","\n","        cond = Image.open(str(image))\n","        ret, mask = cv2.threshold(np.array(cond.split()[-1]), 0, 255, cv2.THRESH_BINARY)\n","        x, y, w, h = cv2.boundingRect(mask)\n","        image_filename = \"original\" + image.suffix\n","\n","        # optional background removal step\n","        if remove_background:\n","            rembg_session = rembg.new_session()\n","            cond = rembg.remove(cond, session=rembg_session)\n","            # image should be a png after background removal\n","            image_filename += \".png\"\n","\n","        if return_intermediate_images:\n","            temp_original = f\"/tmp/{image_filename}\"\n","            cond.save(temp_original)\n","            outputs.append(temp_original)\n","\n","        all_results = self.pipeline(cond, num_inference_steps=100).images[0]\n","        side_len = all_results.width//2\n","        subimages = [all_results.crop((x, y, x + side_len, y+side_len)) for y in range(0, all_results.height, side_len) for x in range(0, all_results.width, side_len)]\n","        for i, output_img in enumerate(subimages):\n","            filename = f\"/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output{i+1}.png\"\n","            output_img.save(filename)\n","            outputs.append(filename)\n","\n","        return([Path(output) for output in outputs])\n","\n","\n","# Predictor 인스턴스 생성\n","predictor = Predictor()\n","\n","# 모델 설정\n","predictor.setup()\n","\n","# 이미지 변환 실행\n","result_paths = predictor.predict(image=Path(\"/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Input/img006.jpg\"), remove_background=True, return_intermediate_images=False)\n","\n","# 결과 경로 출력\n","for path in result_paths:\n","    print(path)\n"],"metadata":{"id":"_kt7SNxq-fN8","colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["2190fbf0b9334f428537a6757f7bf156","2f72b7aa82fe4d1f8bb999c8d63fa829","6604e613b7524c92a214713ef9cb3515","04840bf9d8da48aca75b2a951cf2e185","14b59625954f4947a77e2c3af9a6fe7b","a80b906daf6b46e7802650093abef712","addb2bfc096f4843bb83c0caec59b395","f64a9ad23e124c3aa9f5c9ffe873d21b","3c6f3001385b4e37800451953e526765","8ccb2d1fd4194d11887b6e199c9bacc4","2f1ce1464e5b4d5a809213a6beee1b0a","d79b33462bc0453d9e71e30aa8cbbb0f","72831fb763594a3ca7946f246cf9420c","79b7f66e16a64616a369760b71223aad","97289a8d63a443c08744a6443d020656","98f2c1644e8845e88735e1a7ae6ccd45","96abc68dfc1b4d1cb285b6e7dcee6e07","b8714f1687864417a26359058ededa42","7c41f5fefed0404bbfee41951a38a36a","7add9091de3f4e2ab1c0b85fcd559dc6","4186acbef681430487246f1004a3921c","74c577cfd0fc4fafb47b187533a2347f","0595cad7840a40b1aef2cf1777b1a2be","90e908be205c4f5aacab72df79576f9e","14ece3422d314c9ab3328ba9471fd34f","d391c9baf71b411b997b1fc2ad39f724","48368938bc2f425e8f263415213d86e1","976afb6ea13f4328b1da0ccfded695bb","ff892b8542db45d7b9edae762021189e","af28a1b2d5194df5a30a2b759a556425","733dad0565a04ed7b132455e42e52f19","5b32e13b805846878b779913a7b56ba7","758201d5cd9e49b4b6ba54ccb701dee6"]},"executionInfo":{"status":"ok","timestamp":1713160875782,"user_tz":-540,"elapsed":210486,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"6926f878-273e-4f8a-eb07-6fad1e1e13b2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2190fbf0b9334f428537a6757f7bf156"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Setting up pipeline...\n"]},{"output_type":"display_data","data":{"text/plain":["Loading pipeline components...:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d79b33462bc0453d9e71e30aa8cbbb0f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n","100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 104GB/s]\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0595cad7840a40b1aef2cf1777b1a2be"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output1.png\n","/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output2.png\n","/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output3.png\n","/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output4.png\n","/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output5.png\n","/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output6.png\n"]}]},{"cell_type":"markdown","source":["# Zero123++ 모델 사용 이미지들 전처리\n","  - 이미지 동일한 크기 및 비율 조정 (512 * 512)\n","  - 이미지 선명도 및 해상도\n"],"metadata":{"id":"bsFtdZenk-ua"}},{"cell_type":"markdown","source":["## 동일한 크기 및 비율 조정"],"metadata":{"id":"X1wOmN3plP9E"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","# 이미지 로드\n","image_paths = [f'/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output{i}.png' for i in range(1, 7)]\n","\n","# 목표 이미지 크기\n","target_width = 512\n","target_height = 512\n","\n","# 각 이미지에 대해서 크기 및 비율 조정을 수행\n","for i, image_path in enumerate(image_paths):\n","    # 이미지를 읽어옴\n","    image = cv2.imread(image_path)\n","\n","    # 이미지 크기 조정\n","    resized_image = cv2.resize(image, (target_width, target_height))\n","\n","    # 결과 이미지 저장 경로\n","    resized_image_path = f'/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output{i+1}.png'\n","    cv2.imwrite(resized_image_path, resized_image)\n","\n","    # 결과 확인\n","    print(f'Image {i+1} resized to {target_width}x{target_height}, saved to:', resized_image_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4U_phBClPW_","executionInfo":{"status":"ok","timestamp":1712652260423,"user_tz":-540,"elapsed":5,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"8f678519-b90e-4f78-8f69-e53b42df0a5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image 1 resized to 512x512, saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output1.png\n","Image 2 resized to 512x512, saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output2.png\n","Image 3 resized to 512x512, saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output3.png\n","Image 4 resized to 512x512, saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output4.png\n","Image 5 resized to 512x512, saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output5.png\n","Image 6 resized to 512x512, saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output6.png\n"]}]},{"cell_type":"markdown","source":["##  이미지 샤프닝"],"metadata":{"id":"G6yjVt42nPiR"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","# 이미지 로드\n","image_paths = [f'/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output{i}.png' for i in range(1, 7)]\n","\n","# 각 이미지에 대해서 샤프닝을 수행\n","for i, image_path in enumerate(image_paths):\n","    # 이미지를 읽어옴\n","    image = cv2.imread(image_path)\n","\n","    # 샤프닝을 위한 커널 정의\n","    kernel_sharpening = np.array([[-1, -1, -1],\n","                                  [-1,  9, -1],\n","                                  [-1, -1, -1]])\n","\n","    # 이미지에 샤프닝 적용\n","    sharpened_image = cv2.filter2D(image, -1, kernel_sharpening)\n","\n","    # 결과 이미지 저장 경로\n","    sharpened_image_path = f'/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output{i+1}.png'\n","    cv2.imwrite(sharpened_image_path, sharpened_image)\n","\n","    # 결과 확인\n","    print(f'Image {i+1} sharpened and saved to:', sharpened_image_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4S7wNrmnP2Y","executionInfo":{"status":"ok","timestamp":1712652260930,"user_tz":-540,"elapsed":511,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"63eb3038-3264-4f54-b04f-13e0209ce471"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image 1 sharpened and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output1.png\n","Image 2 sharpened and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output2.png\n","Image 3 sharpened and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output3.png\n","Image 4 sharpened and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output4.png\n","Image 5 sharpened and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output5.png\n","Image 6 sharpened and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output6.png\n"]}]},{"cell_type":"markdown","source":["## 잡음 제거"],"metadata":{"id":"fr8cE7BFnQKX"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","# 이미지 로드\n","image_paths = [f'/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output{i}.png' for i in range(1, 7)]\n","\n","# 각 이미지에 대해서 잡음 제거를 수행\n","for i, image_path in enumerate(image_paths):\n","    # 이미지를 읽어옴\n","    image = cv2.imread(image_path)\n","\n","    # Gaussian Blur 적용\n","    # (5, 5)는 Gaussian Kernel의 크기, 0은 표준 편차를 자동으로 계산하게 함\n","    denoised_image = cv2.GaussianBlur(image, (5, 5), 0)\n","\n","    # 결과 이미지 저장 경로\n","    denoised_image_path = f'/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output{i+1}.png'\n","    cv2.imwrite(denoised_image_path, denoised_image)\n","\n","    # 결과 확인\n","    print(f'Image {i+1} denoised and saved to:', denoised_image_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G-2U-bg2nQiU","executionInfo":{"status":"ok","timestamp":1712652260930,"user_tz":-540,"elapsed":5,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"64b2de28-bc73-411a-bf42-f2269762ff08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image 1 denoised and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output1.png\n","Image 2 denoised and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output2.png\n","Image 3 denoised and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output3.png\n","Image 4 denoised and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output4.png\n","Image 5 denoised and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output5.png\n","Image 6 denoised and saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output6.png\n"]}]},{"cell_type":"markdown","source":["# DUSt3R 사용 코드"],"metadata":{"id":"EpSE5pTuTO2H"}},{"cell_type":"code","source":["#!/usr/bin/env python3\n","\n","# 필요한 라이브러리 및 모듈을 임포트합니다.\n","import os\n","import torch\n","import numpy as np\n","import copy\n","import trimesh\n","from scipy.spatial.transform import Rotation\n","\n","from dust3r.inference import inference, load_model\n","from dust3r.image_pairs import make_pairs\n","from dust3r.utils.image import load_images\n","from dust3r.utils.device import to_numpy\n","from dust3r.viz import add_scene_cam, CAM_COLORS, OPENGL, pts3d_to_trimesh, cat_meshes\n","from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n","\n","# 특정 GPU 설정을 위한 torch 설정입니다. (Ampere GPU와 PyTorch 1.12 이상 버전에서 사용)\n","torch.backends.cuda.matmul.allow_tf32 = True\n","batch_size = 1  # 배치 사이즈를 1로 설정합니다.\n","\n","# 3D 장면 출력을 GLB 파일 형식으로 변환하는 함수입니다.\n","def _convert_scene_output_to_glb(outdir, imgs, pts3d, mask, focals, cams2world, cam_size=0.05,\n","                                 cam_color=None, as_pointcloud=False,\n","                                 transparent_cams=False):\n","    assert len(pts3d) == len(mask) <= len(imgs) <= len(cams2world) == len(focals)\n","    pts3d = to_numpy(pts3d)\n","    imgs = to_numpy(imgs)\n","    focals = to_numpy(focals)\n","    cams2world = to_numpy(cams2world)\n","\n","    scene = trimesh.Scene()\n","\n","    if as_pointcloud:\n","        pts = np.concatenate([p[m] for p, m in zip(pts3d, mask)])\n","        col = np.concatenate([p[m] for p, m in zip(imgs, mask)])\n","        pct = trimesh.PointCloud(pts.reshape(-1, 3), colors=col.reshape(-1, 3))\n","        scene.add_geometry(pct)\n","    else:\n","        meshes = []\n","        for i in range(len(imgs)):\n","            meshes.append(pts3d_to_trimesh(imgs[i], pts3d[i], mask[i]))\n","        mesh = trimesh.Trimesh(**cat_meshes(meshes))\n","        scene.add_geometry(mesh)\n","\n","    # 카메라를 추가하는 코드 부분을 제거했습니다.\n","\n","    rot = np.eye(4)\n","    rot[:3, :3] = Rotation.from_euler('y', np.deg2rad(180)).as_matrix()\n","    scene.apply_transform(np.linalg.inv(cams2world[0] @ OPENGL @ rot))\n","    outfile = os.path.join(outdir, 'scene.glb')\n","    scene.export(file_obj=outfile)\n","    return outfile\n","\n","\n","# 이미지들로부터 3D 모델을 처리하고 생성하는 메인 함수입니다.\n","def process_images_to_3d_model(input_image_paths, output_file_path, weights_path, device='cuda'):\n","    # 모델을 로드합니다.\n","    model = load_model(weights_path, device, verbose=False)\n","\n","    # 입력 이미지들을 로드합니다.\n","    imgs = load_images(input_image_paths, size=512, verbose=False)\n","\n","    # 이미지 쌍을 생성합니다.\n","    pairs = make_pairs(imgs, scene_graph='complete', prefilter=None, symmetrize=True)\n","    # 추론을 수행합니다.\n","    output = inference(pairs, model, device, batch_size=batch_size, verbose=False)\n","\n","    # 글로벌 정렬을 수행하여 3D 장면을 생성합니다.\n","    scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer, verbose=False)\n","    loss = scene.compute_global_alignment(init='mst', niter=1000, schedule='linear', lr=0.01)\n","\n","    # 필요한 후처리를 수행합니다.\n","    scene = scene.clean_pointcloud()\n","    scene = scene.mask_sky()\n","\n","    rgbimg = scene.imgs\n","    focals = scene.get_focals().cpu()\n","    cams2world = scene.get_im_poses().cpu()\n","    pts3d = to_numpy(scene.get_pts3d())\n","    scene.min_conf_thr = float(scene.conf_trf(torch.tensor(3.0)))\n","    msk = to_numpy(scene.get_masks())\n","\n","    # 최종적으로 GLB 파일을 생성합니다.\n","    _convert_scene_output_to_glb(os.path.dirname(output_file_path), rgbimg, pts3d, msk, focals, cams2world, as_pointcloud=False,\n","                                 transparent_cams=False, cam_size=0.05)\n","\n","if __name__ == '__main__':\n","\n","    # 입력 이미지 경로와 출력 파일 경로, 가중치 경로를 설정합니다.\n","    input_image_paths = []\n","    for i in range(1,4):\n","        input_image_paths.append(f\"/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output{i}.png\")\n","\n","    output_file_path = '/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Output/output_model.glb'\n","    weights_path = '/content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth'\n","\n","    # 이미지들로부터 3D 모델을 처리하고 생성합니다.\n","    process_images_to_3d_model(input_image_paths, output_file_path, weights_path)\n"],"metadata":{"id":"btsnEu0bYOWq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------"],"metadata":{"id":"7-KNL2kj6kct"}},{"cell_type":"markdown","source":["# 원라인 코드"],"metadata":{"id":"i1sHTBwYEn7t"}},{"cell_type":"code","source":["import os\n","import subprocess\n","from typing import List\n","import cv2\n","import rembg\n","import torch\n","from cog import BasePredictor, Input, Path\n","from diffusers import DiffusionPipeline, EulerAncestralDiscreteScheduler\n","from PIL import Image\n","import numpy as np\n","import cv2\n","import os\n","import torch\n","import trimesh\n","from scipy.spatial.transform import Rotation\n","from dust3r.inference import inference, load_model\n","from dust3r.image_pairs import make_pairs\n","from dust3r.utils.image import load_images\n","from dust3r.utils.device import to_numpy\n","from dust3r.viz import add_scene_cam, CAM_COLORS, OPENGL, pts3d_to_trimesh, cat_meshes\n","from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n","\n","# Zero123++ 모델 생성자\n","class Predictor(BasePredictor):\n","    def setup(self) -> None:\n","        \"\"\"Load the model into memory to make running multiple predictions efficient\"\"\"\n","\n","        if not os.path.exists(\"weights\"):\n","            os.mkdir(\"weights\")\n","\n","\n","        print(\"Setting up pipeline...\")\n","\n","        self.pipeline = DiffusionPipeline.from_pretrained(\n","            f\"{os.getcwd()}/weights/zero123plusplus\",\n","            custom_pipeline=f\"{os.getcwd()}/diffusers-support/\",\n","            torch_dtype=torch.float16,\n","            local_files_only=True\n","        )\n","        self.pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(\n","            self.pipeline.scheduler.config, timestep_spacing='trailing'\n","        )\n","        self.pipeline.to('cuda:0')\n","\n","    def predict(\n","        self,\n","        image: Path = Input(description=\"Input image. Aspect ratio should be 1:1. Recommended resolution is >= 320x320 pixels.\"),\n","        remove_background: bool = Input(description=\"Remove the background of the input image\", default=False),\n","        return_intermediate_images: bool = Input(description=\"Return the intermediate images together with the output images\", default=False),\n","        Interim_deliverables: str = Input(),\n","        ) -> List[Path]:\n","        \"\"\"Run a single prediction on the model\"\"\"\n","        outputs = []\n","\n","        cond = Image.open(str(image))\n","        ret, mask = cv2.threshold(np.array(cond.split()[-1]), 0, 255, cv2.THRESH_BINARY)\n","        x, y, w, h = cv2.boundingRect(mask)\n","        image_filename = \"original\" + image.suffix\n","\n","        # optional background removal step\n","        if remove_background:\n","            rembg_session = rembg.new_session()\n","            cond = rembg.remove(cond, session=rembg_session)\n","            # image should be a png after background removal\n","            image_filename += \".png\"\n","\n","        if return_intermediate_images:\n","            temp_original = f\"/tmp/{image_filename}\"\n","            cond.save(temp_original)\n","            outputs.append(temp_original)\n","\n","        all_results = self.pipeline(cond, num_inference_steps=100).images[0]\n","        side_len = all_results.width//2\n","        subimages = [all_results.crop((x, y, x + side_len, y+side_len)) for y in range(0, all_results.height, side_len) for x in range(0, all_results.width, side_len)]\n","        for i, output_img in enumerate(subimages):\n","            filename = f\"{Interim_deliverables}/output{i+1}.png\"\n","            output_img.save(filename)\n","            outputs.append(filename)\n","\n","        return([Path(output) for output in outputs])\n","\n","# 이미지 크기 및 비율 맞추기\n","def Image_preprocessing(image_paths):\n","\n","  # 목표 이미지 크기\n","  target_width = 512\n","  target_height = 512\n","\n","  # 각 이미지에 대해서 크기 및 비율 조정을 수행\n","  for i, image_path in enumerate(image_paths):\n","      # 이미지를 읽어옴\n","      image = cv2.imread(image_path)\n","\n","      # 샤프닝을 위한 커널 정의\n","      kernel_sharpening = np.array([[-1, -1, -1],\n","                                    [-1,  9, -1],\n","                                    [-1, -1, -1]])\n","\n","      # 이미지 크기 조정\n","      resized_image = cv2.resize(image, (target_width, target_height))\n","\n","      # 이미지에 샤프닝 적용\n","      sharpened_image = cv2.filter2D(resized_image, -1, kernel_sharpening)\n","\n","      # Gaussian Blur 적용\n","      # (5, 5)는 Gaussian Kernel의 크기, 0은 표준 편차를 자동으로 계산하게 함\n","      denoised_image = cv2.GaussianBlur(sharpened_image, (5, 5), 0)\n","\n","      cv2.imwrite(image_path, denoised_image)\n","      # 결과 확인\n","      print(f'Image {i+1} saved to:', image_path)\n","\n","# 3D 장면 출력을 GLB 파일 형식으로 변환하는 함수입니다.\n","def _convert_scene_output_to_glb(outdir, imgs, pts3d, mask, focals, cams2world, cam_size=0.05,\n","                                 cam_color=None, as_pointcloud=False,\n","                                 transparent_cams=False):\n","    assert len(pts3d) == len(mask) <= len(imgs) <= len(cams2world) == len(focals)\n","    pts3d = to_numpy(pts3d)\n","    imgs = to_numpy(imgs)\n","    focals = to_numpy(focals)\n","    cams2world = to_numpy(cams2world)\n","\n","    scene = trimesh.Scene()\n","\n","    if as_pointcloud:\n","        pts = np.concatenate([p[m] for p, m in zip(pts3d, mask)])\n","        col = np.concatenate([p[m] for p, m in zip(imgs, mask)])\n","        pct = trimesh.PointCloud(pts.reshape(-1, 3), colors=col.reshape(-1, 3))\n","        scene.add_geometry(pct)\n","    else:\n","        meshes = []\n","        for i in range(len(imgs)):\n","            meshes.append(pts3d_to_trimesh(imgs[i], pts3d[i], mask[i]))\n","        mesh = trimesh.Trimesh(**cat_meshes(meshes))\n","        scene.add_geometry(mesh)\n","\n","    rot = np.eye(4)\n","    rot[:3, :3] = Rotation.from_euler('y', np.deg2rad(180)).as_matrix()\n","    scene.apply_transform(np.linalg.inv(cams2world[0] @ OPENGL @ rot))\n","    outfile = os.path.join(outdir, 'scene.glb')\n","    scene.export(file_obj=outfile)\n","    return outfile\n","\n","\n","# 이미지들로부터 3D 모델을 처리하고 생성하는 메인 함수입니다.\n","def process_images_to_3d_model(input_image_paths, output_file_path, weights_path, device='cuda'):\n","    # 모델을 로드합니다.\n","    model = load_model(weights_path, device, verbose=False)\n","\n","    # 입력 이미지들을 로드합니다.\n","    imgs = load_images(input_image_paths, size=512, verbose=False)\n","\n","    # 이미지 쌍을 생성합니다.\n","    pairs = make_pairs(imgs, scene_graph='complete', prefilter=None, symmetrize=True)\n","    # 추론을 수행합니다.\n","    output = inference(pairs, model, device, batch_size=batch_size, verbose=False)\n","\n","    # 글로벌 정렬을 수행하여 3D 장면을 생성합니다.\n","    scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer, verbose=False)\n","    loss = scene.compute_global_alignment(init='mst', niter=500, schedule='linear', lr=0.01)\n","\n","    # 필요한 후처리를 수행합니다.\n","    scene = scene.clean_pointcloud()\n","    scene = scene.mask_sky()\n","\n","    rgbimg = scene.imgs\n","    focals = scene.get_focals().cpu()\n","    cams2world = scene.get_im_poses().cpu()\n","    pts3d = to_numpy(scene.get_pts3d())\n","    scene.min_conf_thr = float(scene.conf_trf(torch.tensor(3.0)))\n","    msk = to_numpy(scene.get_masks())\n","\n","    # 최종적으로 GLB 파일을 생성합니다.\n","    _convert_scene_output_to_glb(os.path.dirname(output_file_path), rgbimg, pts3d, msk, focals, cams2world, as_pointcloud=False,\n","                                 transparent_cams=False, cam_size=0.05)\n","\n","def run(input_path, Interim_deliverables, output_path, weights_path):\n","  # Predictor 인스턴스 생성\n","  predictor = Predictor()\n","\n","  # 모델 설정\n","  predictor.setup()\n","\n","  # 이미지 변환 실행\n","  result_paths = predictor.predict(image=Path(input_path), remove_background=True, return_intermediate_images=False,Interim_deliverables=Interim_deliverables)\n","\n","  # 경로 str화\n","  Interim_deliverables_paths = []\n","  for path in result_paths:\n","    Interim_deliverables_paths.append(str(path))\n","\n","  # 생성된 이미지 전처리\n","  Image_preprocessing(Interim_deliverables_paths)\n","\n","  # 특정 GPU 설정을 위한 torch 설정입니다.\n","  torch.backends.cuda.matmul.allow_tf32 = True\n","  batch_size = 1  # 배치 사이즈를 1로 설정합니다.\n","\n","  # 이미지들로부터 3D 모델을 처리하고 생성합니다.\n","  process_images_to_3d_model(Interim_deliverables_paths, output_path, weights_path)\n","\n","weights_path = f\"{os.getcwd()}/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n","input = f\"{os.getcwd()}/Data/Input/img006.jpg\"\n","Interim_deliverables = f\"{os.getcwd()}/Data/Interim_deliverables\"\n","output_file_path = f\"{os.getcwd()}/Data/Output/output_model.glb\"\n","run(input, Interim_deliverables, output_file_path, weights_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["05eef6e9be30431f9e0a7722692d3425","b995b25286654733a441453302c2ed07","cd3d02767f0b46f7aa38147794191f7e","b1150188aefc4d28a12609c5671c38e3","96a4f20bd2514d63a5c9574097b6874a","958f396e296a4ec08579b973f29aaa39","8905f353f9fc4404a77db6f7bdaa7224","5672744e1c37479ab9663c894b5e77e7","4f6ad8f0b72e42fda42eceaf8ef2694e","c462023ef6394d428fa9d7a32319bff6","95058e00f8e149fa9610b45534687272","b30c1598bf6741bab46152dfa31c282d","e013ed9cb85547bab105e2f1c3246813","2f6cda8207144b6da64893a5c14f8e5c","469d9f1342de475aa54b2f93b15b6168","854d90fc0b8941d69d522bbfd185f01a","e7f2730561714d8fa4225e4e35b88a93","c00f46d7edd844dead3ebc01ef9b5e27","d1c08b8585e94b18ab9339b2873dadf1","1e4b7f7ae08a4e2191de31869898f473","86a727e3b8354092b08baf7e2a7145a0","b0d9fd95a2ce4320bfb4a71d6f5fd7f2"]},"id":"58cpz56qEnnW","executionInfo":{"status":"ok","timestamp":1713165061048,"user_tz":-540,"elapsed":174480,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"1f4878e3-b820-4fd3-dce0-7a207408c0a3"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up pipeline...\n"]},{"output_type":"display_data","data":{"text/plain":["Loading pipeline components...:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05eef6e9be30431f9e0a7722692d3425"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b30c1598bf6741bab46152dfa31c282d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Image 1 saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output1.png\n","Image 2 saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output2.png\n","Image 3 saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output3.png\n","Image 4 saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output4.png\n","Image 5 saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output5.png\n","Image 6 saved to: /content/drive/MyDrive/TeamProjects/DimensionalPioneers/Total/Data/Interim_deliverables/output6.png\n"]}]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------"],"metadata":{"id":"Jvokzl2pEnCP"}},{"cell_type":"markdown","source":["## 기존 dust3r 데모 코드(참고용)"],"metadata":{"id":"5ugqIwJYYPMx"}},{"cell_type":"code","source":["#!/usr/bin/env python3\n","# Copyright (C) 2024-present Naver Corporation. All rights reserved.\n","# Licensed under CC BY-NC-SA 4.0 (non-commercial use only).\n","#\n","# --------------------------------------------------------\n","# gradio demo\n","# --------------------------------------------------------\n","import argparse\n","import gradio\n","import os\n","import torch\n","import numpy as np\n","import tempfile\n","import functools\n","import trimesh\n","import copy\n","from scipy.spatial.transform import Rotation\n","\n","from dust3r.inference import inference, load_model\n","from dust3r.image_pairs import make_pairs\n","from dust3r.utils.image import load_images, rgb\n","from dust3r.utils.device import to_numpy\n","from dust3r.viz import add_scene_cam, CAM_COLORS, OPENGL, pts3d_to_trimesh, cat_meshes\n","from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n","\n","import matplotlib.pyplot as pl\n","pl.ion()\n","\n","torch.backends.cuda.matmul.allow_tf32 = True  # for gpu >= Ampere and pytorch >= 1.12\n","batch_size = 1\n","\n","\n","def get_args_parser():\n","    parser = argparse.ArgumentParser()\n","    parser_url = parser.add_mutually_exclusive_group()\n","    parser_url.add_argument(\"--local_network\", action='store_true', default=False,\n","                            help=\"make app accessible on local network: address will be set to 0.0.0.0\")\n","    parser_url.add_argument(\"--server_name\", type=str, default=None, help=\"server url, default is 127.0.0.1\")\n","    parser.add_argument(\"--image_size\", type=int, default=512, choices=[512, 224], help=\"image size\")\n","    parser.add_argument(\"--server_port\", type=int, help=(\"will start gradio app on this port (if available). \"\n","                                                         \"If None, will search for an available port starting at 7860.\"),\n","                        default=None)\n","    parser.add_argument(\"--weights\", type=str, required=True, help=\"path to the model weights\")\n","    parser.add_argument(\"--device\", type=str, default='cuda', help=\"pytorch device\")\n","    parser.add_argument(\"--tmp_dir\", type=str, default=None, help=\"value for tempfile.tempdir\")\n","    parser.add_argument(\"--silent\", action='store_true', default=False,\n","                        help=\"silence logs\")\n","    return parser\n","\n","\n","def _convert_scene_output_to_glb(outdir, imgs, pts3d, mask, focals, cams2world, cam_size=0.05,\n","                                 cam_color=None, as_pointcloud=False,\n","                                 transparent_cams=False, silent=False):\n","    assert len(pts3d) == len(mask) <= len(imgs) <= len(cams2world) == len(focals)\n","    pts3d = to_numpy(pts3d)\n","    imgs = to_numpy(imgs)\n","    focals = to_numpy(focals)\n","    cams2world = to_numpy(cams2world)\n","\n","    scene = trimesh.Scene()\n","\n","    # full pointcloud\n","    if as_pointcloud:\n","        pts = np.concatenate([p[m] for p, m in zip(pts3d, mask)])\n","        col = np.concatenate([p[m] for p, m in zip(imgs, mask)])\n","        pct = trimesh.PointCloud(pts.reshape(-1, 3), colors=col.reshape(-1, 3))\n","        scene.add_geometry(pct)\n","    else:\n","        meshes = []\n","        for i in range(len(imgs)):\n","            meshes.append(pts3d_to_trimesh(imgs[i], pts3d[i], mask[i]))\n","        mesh = trimesh.Trimesh(**cat_meshes(meshes))\n","        scene.add_geometry(mesh)\n","\n","    # add each camera\n","    for i, pose_c2w in enumerate(cams2world):\n","        if isinstance(cam_color, list):\n","            camera_edge_color = cam_color[i]\n","        else:\n","            camera_edge_color = cam_color or CAM_COLORS[i % len(CAM_COLORS)]\n","        add_scene_cam(scene, pose_c2w, camera_edge_color,\n","                      None if transparent_cams else imgs[i], focals[i],\n","                      imsize=imgs[i].shape[1::-1], screen_width=cam_size)\n","\n","    rot = np.eye(4)\n","    rot[:3, :3] = Rotation.from_euler('y', np.deg2rad(180)).as_matrix()\n","    scene.apply_transform(np.linalg.inv(cams2world[0] @ OPENGL @ rot))\n","    outfile = os.path.join(outdir, 'scene.glb')\n","    if not silent:\n","        print('(exporting 3D scene to', outfile, ')')\n","    scene.export(file_obj=outfile)\n","    return outfile\n","\n","\n","def get_3D_model_from_scene(outdir, silent, scene, min_conf_thr=3, as_pointcloud=False, mask_sky=False,\n","                            clean_depth=False, transparent_cams=False, cam_size=0.05):\n","    \"\"\"\n","    extract 3D_model (glb file) from a reconstructed scene\n","    \"\"\"\n","    if scene is None:\n","        return None\n","    # post processes\n","    if clean_depth:\n","        scene = scene.clean_pointcloud()\n","    if mask_sky:\n","        scene = scene.mask_sky()\n","\n","    # get optimized values from scene\n","    rgbimg = scene.imgs\n","    focals = scene.get_focals().cpu()\n","    cams2world = scene.get_im_poses().cpu()\n","    # 3D pointcloud from depthmap, poses and intrinsics\n","    pts3d = to_numpy(scene.get_pts3d())\n","    scene.min_conf_thr = float(scene.conf_trf(torch.tensor(min_conf_thr)))\n","    msk = to_numpy(scene.get_masks())\n","    return _convert_scene_output_to_glb(outdir, rgbimg, pts3d, msk, focals, cams2world, as_pointcloud=as_pointcloud,\n","                                        transparent_cams=transparent_cams, cam_size=cam_size, silent=silent)\n","\n","\n","def get_reconstructed_scene(outdir, model, device, silent, image_size, filelist, schedule, niter, min_conf_thr,\n","                            as_pointcloud, mask_sky, clean_depth, transparent_cams, cam_size,\n","                            scenegraph_type, winsize, refid):\n","    \"\"\"\n","    from a list of images, run dust3r inference, global aligner.\n","    then run get_3D_model_from_scene\n","    \"\"\"\n","    imgs = load_images(filelist, size=image_size, verbose=not silent)\n","    if len(imgs) == 1:\n","        imgs = [imgs[0], copy.deepcopy(imgs[0])]\n","        imgs[1]['idx'] = 1\n","    if scenegraph_type == \"swin\":\n","        scenegraph_type = scenegraph_type + \"-\" + str(winsize)\n","    elif scenegraph_type == \"oneref\":\n","        scenegraph_type = scenegraph_type + \"-\" + str(refid)\n","\n","    pairs = make_pairs(imgs, scene_graph=scenegraph_type, prefilter=None, symmetrize=True)\n","    output = inference(pairs, model, device, batch_size=batch_size, verbose=not silent)\n","\n","    mode = GlobalAlignerMode.PointCloudOptimizer if len(imgs) > 2 else GlobalAlignerMode.PairViewer\n","    scene = global_aligner(output, device=device, mode=mode, verbose=not silent)\n","    lr = 0.01\n","\n","    if mode == GlobalAlignerMode.PointCloudOptimizer:\n","        loss = scene.compute_global_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n","\n","    outfile = get_3D_model_from_scene(outdir, silent, scene, min_conf_thr, as_pointcloud, mask_sky,\n","                                      clean_depth, transparent_cams, cam_size)\n","\n","    # also return rgb, depth and confidence imgs\n","    # depth is normalized with the max value for all images\n","    # we apply the jet colormap on the confidence maps\n","    rgbimg = scene.imgs\n","    depths = to_numpy(scene.get_depthmaps())\n","    confs = to_numpy([c for c in scene.im_conf])\n","    cmap = pl.get_cmap('jet')\n","    depths_max = max([d.max() for d in depths])\n","    depths = [d/depths_max for d in depths]\n","    confs_max = max([d.max() for d in confs])\n","    confs = [cmap(d/confs_max) for d in confs]\n","\n","    imgs = []\n","    for i in range(len(rgbimg)):\n","        imgs.append(rgbimg[i])\n","        imgs.append(rgb(depths[i]))\n","        imgs.append(rgb(confs[i]))\n","\n","    return scene, outfile, imgs\n","\n","\n","def set_scenegraph_options(inputfiles, winsize, refid, scenegraph_type):\n","    num_files = len(inputfiles) if inputfiles is not None else 1\n","    max_winsize = max(1, (num_files - 1)//2)\n","    if scenegraph_type == \"swin\":\n","        winsize = gradio.Slider(label=\"Scene Graph: Window Size\", value=max_winsize,\n","                                minimum=1, maximum=max_winsize, step=1, visible=True)\n","        refid = gradio.Slider(label=\"Scene Graph: Id\", value=0, minimum=0,\n","                              maximum=num_files-1, step=1, visible=False)\n","    elif scenegraph_type == \"oneref\":\n","        winsize = gradio.Slider(label=\"Scene Graph: Window Size\", value=max_winsize,\n","                                minimum=1, maximum=max_winsize, step=1, visible=False)\n","        refid = gradio.Slider(label=\"Scene Graph: Id\", value=0, minimum=0,\n","                              maximum=num_files-1, step=1, visible=True)\n","    else:\n","        winsize = gradio.Slider(label=\"Scene Graph: Window Size\", value=max_winsize,\n","                                minimum=1, maximum=max_winsize, step=1, visible=False)\n","        refid = gradio.Slider(label=\"Scene Graph: Id\", value=0, minimum=0,\n","                              maximum=num_files-1, step=1, visible=False)\n","    return winsize, refid\n","\n","\n","def main_demo(tmpdirname, model, device, image_size, server_name, server_port, silent=False):\n","    recon_fun = functools.partial(get_reconstructed_scene, tmpdirname, model, device, silent, image_size)\n","    model_from_scene_fun = functools.partial(get_3D_model_from_scene, tmpdirname, silent)\n","    with gradio.Blocks(css=\"\"\".gradio-container {margin: 0 !important; min-width: 100%};\"\"\", title=\"DUSt3R Demo\") as demo:\n","        # scene state is save so that you can change conf_thr, cam_size... without rerunning the inference\n","        scene = gradio.State(None)\n","        gradio.HTML('<h2 style=\"text-align: center;\">DUSt3R Demo</h2>')\n","        with gradio.Column():\n","            inputfiles = gradio.File(file_count=\"multiple\")\n","            with gradio.Row():\n","                schedule = gradio.Dropdown([\"linear\", \"cosine\"],\n","                                           value='linear', label=\"schedule\", info=\"For global alignment!\")\n","                niter = gradio.Number(value=300, precision=0, minimum=0, maximum=5000,\n","                                      label=\"num_iterations\", info=\"For global alignment!\")\n","                scenegraph_type = gradio.Dropdown([\"complete\", \"swin\", \"oneref\"],\n","                                                  value='complete', label=\"Scenegraph\",\n","                                                  info=\"Define how to make pairs\",\n","                                                  interactive=True)\n","                winsize = gradio.Slider(label=\"Scene Graph: Window Size\", value=1,\n","                                        minimum=1, maximum=1, step=1, visible=False)\n","                refid = gradio.Slider(label=\"Scene Graph: Id\", value=0, minimum=0, maximum=0, step=1, visible=False)\n","\n","            run_btn = gradio.Button(\"Run\")\n","\n","            with gradio.Row():\n","                # adjust the confidence threshold\n","                min_conf_thr = gradio.Slider(label=\"min_conf_thr\", value=3.0, minimum=1.0, maximum=20, step=0.1)\n","                # adjust the camera size in the output pointcloud\n","                cam_size = gradio.Slider(label=\"cam_size\", value=0.05, minimum=0.001, maximum=0.1, step=0.001)\n","            with gradio.Row():\n","                as_pointcloud = gradio.Checkbox(value=False, label=\"As pointcloud\")\n","                # two post process implemented\n","                mask_sky = gradio.Checkbox(value=False, label=\"Mask sky\")\n","                clean_depth = gradio.Checkbox(value=True, label=\"Clean-up depthmaps\")\n","                transparent_cams = gradio.Checkbox(value=False, label=\"Transparent cameras\")\n","\n","            outmodel = gradio.Model3D()\n","            outgallery = gradio.Gallery(label='rgb,depth,confidence', columns=3, height=\"100%\")\n","\n","            # events\n","            scenegraph_type.change(set_scenegraph_options,\n","                                   inputs=[inputfiles, winsize, refid, scenegraph_type],\n","                                   outputs=[winsize, refid])\n","            inputfiles.change(set_scenegraph_options,\n","                              inputs=[inputfiles, winsize, refid, scenegraph_type],\n","                              outputs=[winsize, refid])\n","            run_btn.click(fn=recon_fun,\n","                          inputs=[inputfiles, schedule, niter, min_conf_thr, as_pointcloud,\n","                                  mask_sky, clean_depth, transparent_cams, cam_size,\n","                                  scenegraph_type, winsize, refid],\n","                          outputs=[scene, outmodel, outgallery])\n","            min_conf_thr.release(fn=model_from_scene_fun,\n","                                 inputs=[scene, min_conf_thr, as_pointcloud, mask_sky,\n","                                         clean_depth, transparent_cams, cam_size],\n","                                 outputs=outmodel)\n","            cam_size.change(fn=model_from_scene_fun,\n","                            inputs=[scene, min_conf_thr, as_pointcloud, mask_sky,\n","                                    clean_depth, transparent_cams, cam_size],\n","                            outputs=outmodel)\n","            as_pointcloud.change(fn=model_from_scene_fun,\n","                                 inputs=[scene, min_conf_thr, as_pointcloud, mask_sky,\n","                                         clean_depth, transparent_cams, cam_size],\n","                                 outputs=outmodel)\n","            mask_sky.change(fn=model_from_scene_fun,\n","                            inputs=[scene, min_conf_thr, as_pointcloud, mask_sky,\n","                                    clean_depth, transparent_cams, cam_size],\n","                            outputs=outmodel)\n","            clean_depth.change(fn=model_from_scene_fun,\n","                               inputs=[scene, min_conf_thr, as_pointcloud, mask_sky,\n","                                       clean_depth, transparent_cams, cam_size],\n","                               outputs=outmodel)\n","            transparent_cams.change(model_from_scene_fun,\n","                                    inputs=[scene, min_conf_thr, as_pointcloud, mask_sky,\n","                                            clean_depth, transparent_cams, cam_size],\n","                                    outputs=outmodel)\n","    demo.launch(share=False, server_name=server_name, server_port=server_port)\n","\n","\n","if __name__ == '__main__':\n","    parser = get_args_parser()\n","    args = parser.parse_args()\n","\n","    if args.tmp_dir is not None:\n","        tmp_path = args.tmp_dir\n","        os.makedirs(tmp_path, exist_ok=True)\n","        tempfile.tempdir = tmp_path\n","\n","    if args.server_name is not None:\n","        server_name = args.server_name\n","    else:\n","        server_name = '0.0.0.0' if args.local_network else '127.0.0.1'\n","\n","    model = load_model(args.weights, args.device, verbose=not args.silent)\n","    # dust3r will write the 3D model inside tmpdirname\n","    with tempfile.TemporaryDirectory(suffix='dust3r_gradio_demo') as tmpdirname:\n","        if not args.silent:\n","            print('Outputing stuff in', tmpdirname)\n","        main_demo(tmpdirname, model, args.device, args.image_size, server_name, args.server_port, silent=args.silent)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"id":"vLCtucq-TOWl","executionInfo":{"status":"error","timestamp":1712650065323,"user_tz":-540,"elapsed":1214,"user":{"displayName":"서영우","userId":"09294071105118066082"}},"outputId":"72caef26-cf38-46e7-e993-a6b052d76937"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'RootModel' from 'pydantic' (/usr/local/lib/python3.10/dist-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-b14d2f0d015f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# --------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_templates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/_simple_templates/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimpledropdown\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleDropdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimpleimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimpletextbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleTextbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SimpleDropdown\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SimpleTextbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SimpleImage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/_simple_templates/simpledropdown.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFormComponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/components/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotated_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotatedImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_plot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBarPlot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from gradio.components.base import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mComponent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/components/annotated_image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocumentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocessing_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradioModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwasm_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradioModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradioRootModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_upload_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_in_or_equal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/data_classes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwasm_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIS_WASM\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRootModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# XXX: Currently Pyodide V2 is not available on Pyodide,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'RootModel' from 'pydantic' (/usr/local/lib/python3.10/dist-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["# colmap함수(폐기)"],"metadata":{"id":"ifbq2YeXTKX8"}},{"cell_type":"code","source":["# 환경 변수 설정 (Colab에서는 필요하지 않을 수 있음)\n","import os\n","os.environ['QT_QPA_PLATFORM'] = 'offscreen'\n","\n","# 데이터베이스 파일과 이미지 디렉토리의 경로 설정\n","database_path = \"/content/drive/MyDrive/TeamProjects/DimensionalPioneers/4.zero123/database.db\"\n","image_path = \"/content/drive/MyDrive/TeamProjects/DimensionalPioneers/4.zero123/Result\"\n","output_path = \"/content/drive/MyDrive/TeamProjects/DimensionalPioneers/4.zero123/output\"\n","\n","# 데이터 베이스 초기화\n","if os.path.exists(database_path):\n","    os.remove(database_path)\n","\n","# 디렉토리 생성\n","!mkdir -p \"{output_path}\"\n","\n","# 특징점 추출 (CPU 기반)\n","!colmap feature_extractor --database_path \"{database_path}\" --image_path \"{image_path}\" --SiftExtraction.use_gpu 0 --SiftExtraction.max_image_size 2000 --SiftExtraction.num_threads 4\n","\n","\n","# 특징점 매칭\n","!colmap exhaustive_matcher --database_path \"{database_path}\" --SiftMatching.use_gpu 0 --SiftMatching.max_ratio 0.9 --SiftMatching.max_distance 1\n","\n","# 스파스 재구성\n","!colmap mapper --database_path \"{database_path}\" --image_path \"{image_path}\" --output_path \"{output_path}\"\n"],"metadata":{"id":"YVAMaAuj-lMq"},"execution_count":null,"outputs":[]}]}